{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 201 - Assignment 2\n",
    "\n",
    "Please use this page http://apps.ecs.vuw.ac.nz/submit/DATA201 for submitssion and submit only this single Jupyter notebook with your code added into it at the appropriate places.\n",
    "\n",
    "The due date is **Sunday 5th April, before midnight**.\n",
    "\n",
    "The dataset for this assignment is file **sales_data.csv** which is provided with this notebook.\n",
    "\n",
    "Please choose menu items *Kernel => Restart & Run All* then *File => Save and Checkpoint* in Jupyter before submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "A retail company wants to understand the customer purchase behaviour (specifically, purchase amount) against various products of different categories. They have shared purchase summary of various customers for selected high volume products from last month.\n",
    "The data set also contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), product details (product_id and product category) and total purchase_amount from last month.\n",
    "\n",
    "You need to build a model to predict the purchase amount of customer against various products which will help the company to create personalized offer for customers against different products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "| Variable\t                    | Description                                        |\n",
    "|-------------------------------|----------------------------------------------------|\n",
    "|``User_ID``                    |User ID                                             |\n",
    "|``Product_ID``                 |Product ID                                          |\n",
    "|``Gender``                     |Sex of User                                         |\n",
    "|``Age``                        |Age in bins                                         |\n",
    "|``Occupation``                 |Occupation (Masked)                                 |\n",
    "|``City_Category``              |Category of the City (A, B, C)                      |\n",
    "|``Stay_In_Current_City_Years`` |Number of years stay in current city                |\n",
    "|``Marital_Status``             |Marital Status                                      |\n",
    "|``Product_Category_1``         |Product Category (Masked)                           |\n",
    "|``Product_Category_2``         |Product may belongs to other category also (Masked) |\n",
    "|``Product_Category_3``         |Product may belongs to other category also (Masked) |\n",
    "|``Purchase``                   |Purchase Amount (Target Variable)                   |\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The root mean squared error (RMSE) will be used for model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                            object\n",
       "City_Category                  object\n",
       "Gender                         object\n",
       "Marital_Status                  int64\n",
       "Occupation                      int64\n",
       "Product_Category_1              int64\n",
       "Product_Category_2              int64\n",
       "Product_Category_3              int64\n",
       "Product_ID                      int64\n",
       "Purchase                      float64\n",
       "Stay_In_Current_City_Years     object\n",
       "User_ID                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sales_data.csv\")\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Is there any missing value? [1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "City_Category                 0\n",
       "Gender                        0\n",
       "Marital_Status                0\n",
       "Occupation                    0\n",
       "Product_Category_1            0\n",
       "Product_Category_2            0\n",
       "Product_Category_3            0\n",
       "Product_ID                    0\n",
       "Purchase                      0\n",
       "Stay_In_Current_City_Years    0\n",
       "User_ID                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are no missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Drop attribute `User_ID`. [1 point] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('User_ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. Then convert the following categorical attributes below to numerical values with the rule as below. [4 points]**\n",
    "+ `Gender`: `F`:0, `M`:1\n",
    "+ `Age`: `0-17`:0, `18-25`:1, `26-35`:2, `36-45`:3, `46-50`:4, `51-55`:5, `55+`:6\n",
    "+ `Stay_In_Current_City_Years`: `0`:0, `1`:1, `2`:2, `3`:3, `4+`:4\n",
    "\n",
    "You may want to apply a `lambda` function to each row of a column in the dataframe. Some examples here may be helpful: https://thispointer.com/pandas-apply-apply-a-function-to-each-row-column-in-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>394</td>\n",
       "      <td>15200.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>287</td>\n",
       "      <td>19215.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>15665.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>366</td>\n",
       "      <td>5378.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>521</td>\n",
       "      <td>13055.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age City_Category  Gender  Marital_Status  Occupation  Product_Category_1  \\\n",
       "0    0             A       0               0          10                   1   \n",
       "1    4             B       1               1           7                   1   \n",
       "2    2             A       1               1          20                   1   \n",
       "3    5             A       0               0           9                   5   \n",
       "4    5             A       0               0           9                   2   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Product_ID  Purchase  \\\n",
       "0                   6                  14         394   15200.0   \n",
       "1                   8                  17         287   19215.0   \n",
       "2                   2                   5         214   15665.0   \n",
       "3                   8                  14         366    5378.0   \n",
       "4                   3                   4         521   13055.0   \n",
       "\n",
       "   Stay_In_Current_City_Years  \n",
       "0                           2  \n",
       "1                           2  \n",
       "2                           1  \n",
       "3                           1  \n",
       "4                           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'] = data['Gender'].map({'F':0,'M':1})\n",
    "data['Age'] = data['Age'].map({'0-17':0,'18-25':1, '26-35':2, '36-45':3, '46-50':4, '51-55':5, '55+':6})\n",
    "data['Stay_In_Current_City_Years'] = data['Stay_In_Current_City_Years'].map({'0':0,'1':1, '2':2, '3':3, '4+':4})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Randomly split the current data frame into 2 subsets for training (80%) and test (20%). Use *random_state = 42*. [2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Get the list of numerical predictors (all the attributes in the current data frame except the target, `Purchase`) and the list of categorical predictor. [1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop('Purchase', axis=1)\n",
    "y_train = data_train['Purchase'].copy()\n",
    "\n",
    "X_test = data_test.drop('Purchase', axis=1)\n",
    "y_test = data_test['Purchase'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Create a transformation pipeline including two pipelines handling the following [3 points]**\n",
    "- Numerical *predictors*: apply Standard Scaling\n",
    "- Categorical *predictor*: apply One-hot-encoding\n",
    "\n",
    "You will need to use `ColumnTransformer`. The example in Week 3 lectures may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_onehot = [('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))]\n",
    "nom_pl = Pipeline(nom_onehot)\n",
    "\n",
    "num_impute = SimpleImputer(strategy='mean')\n",
    "num_normalised = MinMaxScaler()\n",
    "num_pl = Pipeline([('imp', num_impute), ('norm', num_normalised)])\n",
    "\n",
    "num_cols = list(X_train.select_dtypes([np.number]).columns)\n",
    "nom_cols = list(set(X_train.columns) - set(num_cols))\n",
    "\n",
    "transformers = [('num', num_pl, num_cols),\n",
    "                ('nom', nom_pl, nom_cols)]\n",
    "\n",
    "col_transform = ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Train and use that transformation pipeline to transform the training data (e.g. for a machine learning model). [2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        , 1.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 1.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 1.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.16666667, 1.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.5       , 1.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 1.        , 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans = col_transform.fit_transform(X_train)\n",
    "X_train_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Use that transformation pipeline to transform the test data (e.g. for testing a machine learning model). [2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 1.        , 1.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.16666667, 1.        , 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.5       , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.33333333, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5       , 1.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_trans = col_transform.transform(X_test)\n",
    "X_test_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Build a Linear Regression model using the training data after transformation and test it on the test data. Report the RMSE values on the training and test data. [3 points]**\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Linear Regression Training Set RMSE: 4600\n",
      "Linear Regression Test Set RMSE: 4616\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr_pipeline = Pipeline([('col_trans', col_transform), ('lr', lr)])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "lr_train_pred = lr_pipeline.predict(X_train)\n",
    "lr_test_pred = lr_pipeline.predict(X_test)\n",
    "print(\" Linear Regression Training Set RMSE: %.4g\" % np.sqrt(metrics.mean_squared_error(lr_train_pred, y_train)))\n",
    "print(\"Linear Regression Test Set RMSE: %.4g\" % np.sqrt(metrics.mean_squared_error(lr_test_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Repeat Question 9 using a `KNeighborsRegressor`. Comment on the processing time and performance of the model in this question. [1 point]**\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbours Regressor Training Set RMSE: 3407\n",
      "K Neighbours Regressor Test Set RMSE: 4230\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn_pipeline = Pipeline([('col_trans', col_transform), ('knn', knn)])\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "knn_train_pred  = knn_pipeline.predict(X_train)\n",
    "knn_test_pred = knn_pipeline.predict(X_test)\n",
    "print(\"K Neighbours Regressor Training Set RMSE: %.4g\" % np.sqrt(metrics.mean_squared_error(knn_train_pred, y_train)))\n",
    "print(\"K Neighbours Regressor Test Set RMSE: %.4g\" % np.sqrt(metrics.mean_squared_error(knn_test_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbours Regression is significantly slower than Linear Regression because in KNN each training instance has to be compared with every other training instance one-by-one, this makes it computationally expensive especially when your dataset is wide (a lot of features, which in our instance, it does). It's complexity is n $\\times$ n because each instance has n comparisions. \n",
    "\n",
    "\n",
    "KNN Regression also has poorer performance than the Linear Regression model, as observed by how RMSE for the training and test sets for Linear Regression are near identicial, it means there's little variance in the residuals. KNN Regression on the other hand has a pretty big discrepancy between the RMSE values, most likely due to a very terrible signal-to-noise ratio thanks to our large number of features. KNN works best when it comes to small datasets without too much noise  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.368320610687023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = [31, 150, 400, 284, 121]\n",
    "pretend_votes = [2,4,8,16,32]\n",
    "utilities = [1,2,3,4,5]\n",
    "def score(item_votes):\n",
    "    votes = [iv+pv for (iv,pv) in zip(item_votes,pretend_votes)]\n",
    "    return sum(v*u for (v,u) in zip(votes,utilities))/float(sum(votes))\n",
    "\n",
    "score(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
