{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA201 Mid-term Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use this page http://apps.ecs.vuw.ac.nz/submit/DATA201 for submitssion.\n",
    "\n",
    "The due date is **Friday 22/5/2020 at 4pm**.  \n",
    "\n",
    "(Total 50 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to the Moral Machine website (http://moralmachine.mit.edu/) and do the “Judge” exercise.  Also watch this clip https://www.youtube.com/watch?v=nhCh1pBsS80 about the Moral Machine, driverless cars, and related issues.\n",
    "Then write 200-300 words on how you would approach working on a team of engineers and programmers designing a driverless car with the capability to make choices of the kind that are needed in the Judging exercise.   In your answer consider the ethical choices that are implied - including a discussion of which ones the team **does** have responsibility for, and which ones they **don't**. **(10 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been thinking a lot about this since the discussion on zoom. My current perspective is that a question like that wouldn't be handled by a team of engineers and programmers. That job should be overseen by a committee or board of professionals. Who would implement guidelines and rules that the self-driving cars must adhere to. I wouldn't have the confidence to implement such an algorithm unless I knew that the risk of accidents were very small. A data scientist, however, should not ponder questions about value of life based on discriminatory factors such as age, ethnicity, income etc. \n",
    "\n",
    "It all comes down to how much of life is deterministic and how much of what happens in the real world can be fitted by a model. A data scientist, engineer, programmer should not be given this task, their job isn't to come up with moral answers to moral dilemmas. Their job is to mitigate as much risk as possible while implementing an algorithm that should adhere to some higher level law, guidelines or rules. These guidelines should be universal in the creation of self-driving cars so that there's consistency, accountability and a safeguard when things go wrong. An engineer/programmer etc for example should implement features to increase security and lessen the susceptibility of hacking or other software failures. They should also optimise the algorithms so that they're quick and not computationally expensive. Their job is to build a system and make sure that system is efficient. A data scientist's job could be to design the algorithm but the deterministic questions the algorithm must answer should be already answered but not by a data scientist. It is my hope, however, that machine learning and AI  will be intelligent enough that these questions don't have to be asked.\n",
    "It's an issue not black & white because we're trading lives and like Captain America said \"we don't trade lives\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The following table of relationship status by age group potentially exposes characteristics of the individuals it contains, with one individual at particular risk of disclosure.  Confidentialise the table in two ways (cell suppression to conceal the riskiest cell, and random rounding to base 3) – clearly explain the steps you have taken in each case, and comment on the advantages/disadvantages of the two approaches. **(10 Marks)**\n",
    "\n",
    "Relationship Status by age: \n",
    "\n",
    "| Age Group | Single | Opposite sex couple | Same sex couple | Other | Total |\n",
    "| --- |  --- |  --- |  --- |  --- |  --- | \n",
    "| 15-19 | 0 | 0 | 1 | 0 | 1 |\n",
    "| 20-24 | 8 | 7 | 4 | 2 | 21 |\n",
    "| 25-29 | 14 | 10 | 4 | 0 | 28 |\n",
    "| 30-34 | 7 | 8 | 0 | 1 | 16 |\n",
    "| 34-39 | 3 | 2 | 3 | 1 | 9 |\n",
    "| Total | 32 | 27 | 12 | 4 | 75 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The 15-19yo bracket only contains one instance so there's a possibility of loss of confidentiality we can block out the cell:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Age Group | Single | Opposite sex couple | Same sex couple | Other | Total |\n",
    "| --- |  --- |  --- |  --- |  --- |  --- | \n",
    "| 15-19 | 0 | 0 |  | 0 | 1 |\n",
    "| 20-24 | 8 | 7 | 4 | 2 | 21 |\n",
    "| 25-29 | 14 | 10 | 4 | 0 | 28 |\n",
    "| 30-34 | 7 | 8 | 0 | 1 | 16 |\n",
    "| 34-39 | 3 | 2 | 3 | 1 | 9 |\n",
    "| Total | 32 | 27 | 12 | 4 | 75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But since we only blocked out one cell, the value can be inferred via the row totals so we need to block out another cell:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Age Group | Single | Opposite sex couple | Same sex couple | Other | Total |\n",
    "| --- |  --- |  --- |  --- |  --- |  --- | \n",
    "| 15-19 | 0 |  |  | 0 | 1 |\n",
    "| 20-24 | 8 | 7 | 4 | 2 | 21 |\n",
    "| 25-29 | 14 | 10 | 4 | 0 | 28 |\n",
    "| 30-34 | 7 | 8 | 0 | 1 | 16 |\n",
    "| 34-39 | 3 | 2 | 3 | 1 | 9 |\n",
    "| Total | 32 | 27 | 12 | 4 | 75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However it's still not secure as the values can still be inferred, this time by the column totals, so we'll need to block out another 2 cells in a row:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Age Group | Single | Opposite sex couple | Same sex couple | Other | Total |\n",
    "| --- |  --- |  --- |  --- |  --- |  --- | \n",
    "| 15-19 | 0 |  |  | 0 | 1 |\n",
    "| 20-24 | 8 | 7 | 4 | 2 | 21 |\n",
    "| 25-29 | 14 | 10 | 4 | 0 | 28 |\n",
    "| 30-34 | 7 | 8 | 0 | 1 | 16 |\n",
    "| 34-39 | 3 |  |  | 1 | 9 |\n",
    "| Total | 32 | 27 | 12 | 4 | 75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another way to confidentialise information is to use random rounding where the value as a 2/3 chance of rounding to the nearest multiple of 3, and a 1/3 chance of rounding to the furthest multiple of 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Age Group | Single | Opposite sex couple | Same sex couple | Other | Total |\n",
    "| --- |  --- |  --- |  --- |  --- |  --- | \n",
    "| 15-19 | 0 | 0 | 0 | 0 | 0 |\n",
    "| 20-24 | 9 | 6 | 3 | 3 | 21 |\n",
    "| 25-29 | 12 | 9 | 3 | 0 | 27 |\n",
    "| 30-34 | 6 | 6 | 0 | 0 | 15 |\n",
    "| 34-39 | 3 | 0 | 3 | 0 | 9 |\n",
    "| Total | 33 | 27 | 12 | 3 | 75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Cell Suppresion:**\n",
    "* Simple to perform\n",
    "* Minimal cells affected\n",
    "\n",
    "**Disadvantages of Cell Suppression:**\n",
    "* Additional non-risky cells have to be suppressed to give an acceptable level of anonymity\n",
    "* Susceptible to basic data inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Random Rounding:**\n",
    "* Obscures the data well\n",
    "* Harder to predict the real values \n",
    "* Hides small numbers\n",
    "\n",
    "**Disadvantages of Random Rounding:**\n",
    "* Must be performed over the entire data\n",
    "* Margin values no-longer add up \n",
    "* Possibility of getting distributions of data far from the original\n",
    "* Increases don't scale consistently so attributes with a wider range of values eg. (min 1, max 1000) can have more extreme differences to the original values. A 1 to 3 increase is a 200% increase but a 997 to 999 increase is only a 0.2% increase    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Study the Python code below and its output the answer the questions that follow. **(10 marks)**\n",
    "\n",
    "Code (the dataset is not provided so you should not try running the code):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "print(data.info())\n",
    "print(data.survived.unique())\n",
    "\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape[0])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"%.3f\" % clf.score(X_test, y_test))\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10, iid=False)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(\"%.3f\" % grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1309 entries, 0 to 1308\n",
    "Data columns (total 14 columns):\n",
    "pclass       1309 non-null int64\n",
    "survived     1309 non-null int64\n",
    "name         1309 non-null object\n",
    "sex          1309 non-null object\n",
    "age          1046 non-null float64\n",
    "sibsp        1309 non-null int64\n",
    "parch        1309 non-null int64\n",
    "ticket       1309 non-null object\n",
    "fare         1308 non-null float64\n",
    "cabin        295 non-null object\n",
    "embarked     1307 non-null object\n",
    "boat         486 non-null object\n",
    "body         121 non-null float64\n",
    "home.dest    745 non-null object\n",
    "dtypes: float64(3), int64(4), object(7)\n",
    "memory usage: 143.2+ KB\n",
    "None\n",
    "[1 0]\n",
    "1047\n",
    "0.790\n",
    "{'classifier__C': 0.1, 'preprocessor__num__imputer__strategy': 'mean'}\n",
    "0.798"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   a. How many examples and features are there in the given dataset? (1 mark)\n",
    "    \n",
    "   b. Which feature has the largest number of missing values? How many? (1 mark)\n",
    "\n",
    "   c. Which feature is used as the label for the classification problem in the code? How many classes are there? (1 mark)\n",
    "\n",
    "   d. How many samples are there in the test set? (1 mark)\n",
    "\n",
    "   e. What are the features used for model training? (1 mark)\n",
    "\n",
    "   f. What is the name of the classification algorithm used in the code? (1 mark)\n",
    "\n",
    "   g. What was done to the numerical features before model training? (2 marks)\n",
    "\n",
    "   h. From the outcome of using `GridSearchSV`, what should be done to improve the model `clf`? (1 mark)\n",
    "\n",
    "   i. If the hyperparameters found from using `GridSearchSV` are used, will the accuracy of the model on the test set improve? (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** 1309 examples, 14 features\n",
    "\n",
    "**b.** body with 1188 missing values\n",
    "\n",
    "**c.** survived, 2 classes: 1(survived) and 0(not survived)\n",
    "\n",
    "**d.** $20\\%$ of $1309 = 1309 \\times 0.20 = 261.8 \\implies 262$ \n",
    "\n",
    "**e.** pclass, sex, age, fare, embarked\n",
    "\n",
    "**f.** Logistic Regression\n",
    "\n",
    "**g.** Before model training the numerical features have been transformed such that the distribution of values follows a normal distribution. This is done by normalising the values so that the distribution of data has a mean($\\lambda$) of 0 and a standard deviation($\\sigma$) of 1. The values are also transformed using an imputer which imputes the missing values with the median of the data\n",
    "\n",
    "**h.** Impute the missing numerical values with the mean instead of the median\n",
    "\n",
    "**i.** GridSearchCV is used to find the most optimal model for the classifier, what GridSearchCV yields are the parameters that gave the best validation, so using those hyperparameters **will increase** the model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The purpose of setting the random_state parameter in `train_test_split` is: (select all that apply) **(1 mark)**\n",
    "\n",
    "    a. To avoid predictable splitting of the data\n",
    "    \n",
    "    b. To make experiments easily reproducible by always using the same partitioning of the data\n",
    "    \n",
    "    c. To avoid bias in data splitting\n",
    "    \n",
    "    d. To split the data into similar subsets so that bias is not introduced into the final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Given a dataset with 10,000 observations and 50 features plus one label, what would be the dimensions of X_train, y_train, X_test, and y_test? Assume a train/test split of 75%/25%. **(1 mark)**\n",
    "\n",
    "    a. X_train: (2500, ) ; y_train: (2500, 50) ; X_test: (7500, ) ; y_test: (7500, 50)\n",
    "    \n",
    "    b. X_train: (10000, 28) ; y_train: (10000, ) ; X_test: (10000, 12) ; y_test: (10000, )\n",
    "    \n",
    "    c. X_train: (2500, 50) ; y_train: (2500, ) ; X_test: (7500, 50) ; y_test: (7500, )\n",
    "    \n",
    "    d. X_train: (7500, 50) ; y_train: (7500, ) ; X_test: (2500, 50) ; y_test: (2500, )\n",
    "    \n",
    "    e. None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which of the following is an example of multiclass classification (select all that apply)? **(1 mark)**\n",
    "\n",
    "    a. Classify a set of fruits as apples, oranges, bananas, or lemons\n",
    "    \n",
    "    b. Predict whether an article is relevant to one or more topics (e.g. sports, politics, finance, science)\n",
    "    \n",
    "    c. Predicting both the rating and profit of soon to be released movie\n",
    "    \n",
    "    d. Classify a voice recording as an authorized user or not an authorized user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Looking at the plot below which shows accuracy scores for different values of a regularization parameter *lambda*, what value of *lambda* is the best choice for generalization? **(2 marks)**\n",
    "\n",
    "![](images/lambda_score.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Which of the following is true of cross-validation (select all that apply)? **(1 mark)**\n",
    "\n",
    "    a. Helps prevent knowledge about the test set from leaking into the model\n",
    "    \n",
    "    b. Fits multiple models on different splits of the data\n",
    "    \n",
    "    c. Increases generalization ability and computational complexity\n",
    "    \n",
    "    d. Increases generalization ability and reduces computational complexity\n",
    "    \n",
    "    e. Removes need for training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. A supervised learning model has been built to predict whether someone is infected with a new strain of a virus. The probability of any one person having the virus is 1%. Using accuracy as a metric, what would be a good choice for a baseline accuracy score that the new model would want to outperform? **(1 mark)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$0.01/0.99 = 0.01$ or 1%, the true positives and true negatives should be 1% and 99% respectively with  false positives and false negatives being 0% ideally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Given the following confusion matrix:\n",
    "\n",
    "|                    | Predicted Positive | Predicted Negative |\n",
    "|--------------------|--------------------|--------------------|\n",
    "| Condition Positive |         96         |          4         |\n",
    "| Condition Negative |          8         |         19         |\n",
    "\n",
    "Compute the *accuracy*, *precision*, *recall*, and *specificity* (each to three decimal places) **(4 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**accuracy:** $\\frac{i}{n} = \\frac{TP+TN}{n} = \\frac{96+19}{127} = \\frac{115}{127} = 0.906$\n",
    "\n",
    "**precision:** $\\frac{TP}{TP+FP} = \\frac{96}{96+8} = \\frac{96}{104} = 0.923$\n",
    "\n",
    "**recall:** $\\frac{TP}{P} = \\frac{TP}{TP+FN} = \\frac{96}{96+4} = \\frac{96}{100} = 0.96$\n",
    "\n",
    "**specificity:** $\\frac{TN}{N} = \\frac{TN}{TN+FP} = \\frac{19}{19+8} = \\frac{19}{27} = 0.704$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Given the following models and AUC scores, find the corresponding ROC curve to each model. **(1 mark)**\n",
    "    + Model 1 test set AUC score: 0.91\n",
    "    + Model 2 test set AUC score: 0.50\n",
    "    + Model 3 test set AUC score: 0.56\n",
    "    \n",
    "![](images/ROC.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model1:** ROC1\n",
    "\n",
    "**Model2:** ROC3\n",
    "\n",
    "**Model3:** ROC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. A feature F1 can take certain value: A, B, C, D, E, & F and represents grade of students from a college. Which of the following statement is true in following case? **(1 mark)**\n",
    "\n",
    "    a. Feature F1 is an example of nominal variable.\n",
    "    \n",
    "    b. Feature F1 is an example of ordinal variable.\n",
    "\n",
    "    c. It doesn’t belong to any of the above categories.\n",
    "    \n",
    "    d. Both of a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. [True or False] It is possible for a Pearson correlation between two variables to be zero but their values are still related to each other. **(1 mark)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True:** A Pearson corelation only represents linear relationships, it's still possible for the values to be related non-linearly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Suppose you are given 7 scatter plots from 1 to 7 as below (from left to right) and you want to compare Pearson correlation coefficients between variables of each scatterplot. \n",
    "\n",
    "![](images/corr.png \"\")\n",
    "\n",
    "Consider the following statements about the relative values of the coefficients.\n",
    "\n",
    "   A.\t1<2<3<4\n",
    "   \n",
    "   B.\t1>2>3>4\n",
    "   \n",
    "   C.\t7<6<5<4\n",
    "   \n",
    "   D.\t7>6>5>4\n",
    "\n",
    "Which pair of statements is correct? **(1 mark)**\n",
    "\n",
    "   a. A and C\n",
    "    \n",
    "   b. B and C\n",
    "    \n",
    "   c. A and D\n",
    "    \n",
    "   d. B and D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Run the code in the Notebook cell below and write **one line** of code for each of the following questions **(5 marks)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', SGDClassifier(loss='log', random_state=42))])\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   a. Compute the precision score of the model on the test set (1 mark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   b. Compute the recall score of the model on the test set (1 mark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   c. Predict the class of the last instance in the test set (1 mark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_test)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   d. Print the total number of instances in the test set which are correctly classified (2 marks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Did it two ways incase an import statement counts as a line of code\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pipe.predict(X_test))[0][0]+confusion_matrix(y_test, pipe.predict(X_test))[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second way without the confusion matrix \n",
    "sum(test == pred for test, pred in zip(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
